{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Tutorial \n",
    "Credit to: https://stackabuse.com/text-classification-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show them what the data looks like! Particularly cv001 in negative reviews, has words like GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = load_files(r\"review_polarity/txt_sentoken\")\n",
    "X, y = movie_data.data, movie_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is NEGATIVE, 1 is POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ cuts down all the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capsule trippy hyperspeed action machine from hong kong accomplished tsui hark nvan damme and rodman have nice chemistry the stunt are eyepopping and stuff get blowed up real good what more do you want ni admit wa all set to loathe double team it reeked of cheapjack timing oriented marketing stick dennis rodman in movie quick while he hot and do something about jean claude van damme flagging career while we re at it nsurprise double team transcends it dumb root and turn out to be mess of fun nbring some friend get some pretzel and have blast nvan damme is jack quinn an ex agent who is brought back in for one last mission you think any spy worth his shoe phone would run like hell when he hears those word nbut van damme character ha pregnant wife who also sculptor and some unpleasant pressure get used to get him to come through on this mission nhe been assigned to take down an old enemy terrorist named stavros mickey rourke looking oddly subdued who may be back up to his old trick nin the first showdown between quinn and stavros the movie wear it ambition proudly on it sleeve nonstop action nan amusement park hospital private retired spy retreat most of rome various house plane car and other mode of transport and the coliseum nall become arena for some of the most bone rattling shoot out and punch out filmed nthey are better seen than described and are reason enough to see the film one jaw dropping scene ha van damme taking on man who us switchblade with his foot van damme is good dextrous athlete and fighter but he is often upstaged nthere are other nice touch nstavros and quinn both want the same thing to retire in peace with their family nthat ambition tie them together in various way and also humanizes them bit none of the thing about hk action movie is that there always some form of human element and that carried over into this movie a well nit give weight to scene that would otherwise be forgettable nalso good is dennis rodman playing weapon dealer named yaz character who stick out like fistful of broken finger and who is funny just standing there nrodman is natural on screen he fun to watch especially when slinging bad guy like basketball and deserves to get movie of his own based on what seen here lightweight fast moving entertainment that showcase all of it piece excellently'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X1 = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X2 = tfidfconverter.fit_transform(X1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: research how this works and how to say it concisely, also find out how to show it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X2, y, [i for i in range(2000)], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[405, 1190, 1132, 731, 1754, 1178, 1533, 1303, 1857, 18, 1266, 1543, 249, 191, 721, 1896, 452, 1947, 1544, 1205, 1905, 1235, 799, 1594, 1091, 1357, 479, 1148, 511, 1931, 1257, 1105, 1938, 1750, 1058, 427, 1025, 156, 491, 995, 27, 1326, 1239, 17, 1622, 519, 361, 289, 1790, 1135, 1549, 1327, 76, 579, 279, 935, 475, 1786, 1023, 1556, 842, 1522, 1108, 1369, 47, 794, 918, 1220, 506, 353, 276, 881, 1835, 1703, 333, 1616, 135, 182, 1761, 1501, 930, 107, 390, 1165, 1698, 262, 1732, 260, 487, 303, 53, 1015, 148, 1442, 1580, 1999, 1927, 80, 1854, 264, 1979, 1273, 538, 1529, 37, 896, 1129, 1617, 1276, 878, 386, 1820, 977, 1074, 1542, 648, 1922, 77, 689, 9, 861, 6, 1083, 161, 1600, 1110, 962, 1385, 775, 1174, 823, 145, 240, 215, 1889, 465, 987, 1238, 760, 252, 1633, 781, 1451, 572, 85, 634, 317, 118, 1784, 1876, 443, 1900, 516, 1646, 30, 713, 254, 900, 587, 1317, 1887, 1811, 1121, 1334, 1918, 906, 1635, 1858, 796, 1076, 522, 1411, 124, 187, 517, 1945, 686, 342, 1787, 200, 1421, 1511, 1954, 233, 1620, 1344, 1295, 887, 229, 1893, 1426, 682, 440, 557, 899, 1363, 1981, 384, 1158, 1604, 1018, 655, 436, 921, 1340, 1781, 1610, 1621, 453, 1361, 294, 744, 310, 1188, 220, 376, 1406, 259, 1341, 658, 402, 706, 814, 530, 564, 1666, 1955, 1798, 459, 1834, 654, 34, 1808, 1985, 1717, 1147, 1124, 1557, 629, 1356, 512, 597, 999, 955, 610, 1299, 458, 385, 892, 175, 1991, 1715, 1756, 1694, 1744, 61, 1867, 1632, 1271, 227, 1093, 14, 521, 1150, 501, 1203, 1246, 1957, 1618, 1785, 574, 746, 839, 609, 546, 1005, 745, 223, 1677, 1039, 1492, 1196, 1507, 152, 1003, 688, 773, 677, 1367, 55, 141, 1644, 1256, 202, 933, 575, 982, 723, 1487, 801, 1452, 1044, 1279, 674, 1200, 1901, 393, 217, 1704, 1713, 39, 1088, 66, 1034, 1642, 981, 206, 399, 1471, 1695, 651, 1480, 5, 58, 1775, 1528, 898, 1440, 1358, 92, 1217, 1741, 1654, 1050, 831, 278, 793, 133, 1476, 144, 1906, 1386, 758, 1127, 795, 1926, 1724, 19, 1502, 880, 54, 1892, 1437, 789, 943, 1189, 1281, 1929, 1, 762, 1460, 113, 1222, 1051, 438, 1478, 82, 379, 1212, 1446, 326, 811, 322, 716, 1355, 1579, 461, 425, 1101, 122, 883, 446, 48, 1197, 866, 1374, 1263, 503, 1366, 1752, 298, 52, 1859, 1337, 1336, 638, 360, 1810, 1743, 563]\n"
     ]
    }
   ],
   "source": [
    "print(indices_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'this is crap , but , honestly , what older american audience is going to be able to resist seeing jack lemmon and james garner as bicker- ing ex-presidents ? \\nespecially when their supporting players in- clude dan aykroyd as the current commander in chief , lauren bacall as a former first lady , and john heard as the dan quayle-ish vice president . \\nyup , you\\'re talkin\\' pre-sold property here and , for warner brothers , the perfect fit into their now-ritual grumpy old men holiday slot . \\nfor the non-discriminating viewer , my fellow americans is fine . \\nthe raw star power alone will have audiences applauding this atrocious political- thriller road-comedy . \\n ( they did in mine , heaven help us . ) \\nfor the rest of us , the movie is immediately tiresome . \\nthe tone is terrible and the banter is worse . \\nforget wit-- lemmon and garner merely exchange profanities through most of the movie . \\n ( has anyone counted the number of first penis references ? ) \\nsure , some of the bits are absurdly funny , including a men\\'s room macarena joke , the appearance of an elvis impersonator on a trainload of tarheels , and an all dorothy marching band performing \" over the rainbow \" at a gay men\\'s march . \\nthe get there from here , though , you have to submit to one of the most offensively overbearing musical scores of all time . \\njudas priest , is there a single moment of silence in this film ? \\neven the dialogue gets drowned out . \\nwhat a waste . \\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  28]\n",
      " [ 30 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       208\n",
      "           1       0.85      0.84      0.85       192\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  28]\n",
      " [ 30 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       208\n",
      "           1       0.85      0.84      0.85       192\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
