{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Table Example\n",
    "\n",
    "## Overview\n",
    "\n",
    "The environment is grid of variable size (user defined) that contains a number of obstacles.\n",
    "One agent tries to reach its target starting from the (0, 0) cell.\n",
    "\n",
    "## Algorithm Outline\n",
    "\n",
    "The Q-table is intialized \n",
    "\n",
    "  * For each episode _e_ (from _1_ to _N_)\n",
    "     - New actions are attempted until either the target or an obstacle are reached. The Q-table is updated with new values whenever there is an improved.\n",
    "       \n",
    "At the end of the last episode, the best results are found in the Q-table.\n",
    "\n",
    "_Note that there is absolutely no guarantee that this algorithm will converge\n",
    "or that the result will be optimal_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from visual import Visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "The Q-table is updated and optimized step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from board import Board\n",
    "from agent import QLearningTable\n",
    "\n",
    "\n",
    "def improve_table(env, q, episodes=100, stop_at_goal=False):\n",
    "    # Resulted list for the plotting Episodes via Steps\n",
    "    steps = []\n",
    "\n",
    "    # Summed costs for all episodes in resulted list\n",
    "    all_costs = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        print('Episode ', episode, 'of', episodes)\n",
    "        observation = env.reset()\n",
    "        i = 0\n",
    "        cost = 0\n",
    "        while True:\n",
    "            env.render()  # Update view of environment\n",
    "            action = q.choose_action(str(observation)) # Choose action\n",
    "            observation_, reward, done = env.step(action)  # \n",
    "            cost += q.learn(str(observation), action, reward, str(observation_))\n",
    "            if done:\n",
    "                print(observation_)\n",
    "            observation = observation_\n",
    "            i += 1\n",
    "            if done:  # Episode ends when an obstacle or the target are reached\n",
    "                steps += [i]\n",
    "                all_costs += [cost]\n",
    "                break\n",
    "    env.final()  # Show final route\n",
    "    q.print_q_table()  # Show final Q-table\n",
    "    q.plot_results(steps, all_costs)  # Plot stats\n",
    "\n",
    "def run_example(grid=[(6, 8)], episodes=100, stop_at_goal=False, delay=None, vis=None):\n",
    "    env = Board(grid, delay, stop_at_goal, vis)\n",
    "    q = QLearningTable(actions=list(range(env.n_actions)))\n",
    "    improve_table(env, q, episodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the example\n",
    "Build the environment, and run the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from main_loop import run_example\n",
    "\n",
    "vis = Visual()\n",
    "# grid consists of: RxC(tuple), goal(tuple), obstacles(list of tuples)\n",
    "grid = [(4, 5), (3, 4), [(1, 0), (1, 1), (1, 2), (2, 2), (0, 4), (3, 1)]]\n",
    "episodes=20\n",
    "run_example(grid, episodes, vis=vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}